---
title: "Part 1"
author: "Jane Huber"
output: 
  html_document:
    code_folding: hide
    df_print: paged
    theme: sandstone
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE)
library(tidyverse)
library(lubridate)
#devtools::install_github("cmf-uchicago/cmfproperty")
library(cmfproperty)
library(purrr)
library(gridExtra)
library(ggplot2)

pacman::p_load(ggridges)

```

Template file. Code will be included in folded blocks in the output to facilitate grading. Please knit this file and commit both the rmd and the html output. If you add external files to your analysis, please commit them to the files folder in this repository. NOTE: please do not commit large (15MB+) files to GitHub. Instead please denote the origin of the files in your code. 

```{r download-data, include=FALSE}

con <- DBI::dbConnect(RSQLite::SQLite(), "../database/detroit.sqlite")

# convert to tibble
sales <- dplyr::tbl(con, 'sales') %>% dplyr::collect()
assessments <- dplyr::tbl(con, 'assessments') %>% dplyr::collect()
blight <- dplyr::tbl(con, 'blight') %>% dplyr::collect()
parcels <- dplyr::tbl(con, 'parcels') %>% dplyr::collect()
parcels_historic <- dplyr::tbl(con, 'parcels_historic') %>% dplyr::collect()
foreclosures <- dplyr::tbl(con, 'foreclosures') %>% dplyr::collect()

# sql query

#sales_per_year <- dplyr::tbl(con, 'sales') %>% count(year(sale_date))

#dplyr::tbl(con, 'sales') %>% count(year(sale_date)) %>% show_query()

```

# Section A: Exploratory Data Analysis


Conduct an exploratory data analysis of homes in Detroit. Offer an overview of relevant trends in the data and data quality issues. Contextualize your analysis with key literature on properties in Detroit.
https://scholarship.law.uci.edu/ucilr/vol9/iss4/3/
https://harris.uchicago.edu/files/evalrespropertytaxasdetroit20162018.pdf

- What are tools to use for exploratory data analysis? [Chapter 6 of the textbook]

- Step 1: Look into the data, figure out what's going on for each.
Note: Honestly not great descctiptions of what different statuses mean. Difficulty in interpreting how I can use these; I'll have to do some poking around in order to make determinations.

- Step 2: clean data so it can be used for analysis later on.
```{r data-exploration-cleaning, include = FALSE}

# Sales
sales_clean <- 
  sales %>% 
  select(c(parcel_num, sale_date, sale_price, sale_terms)) %>% 
  mutate(sale_date = as.Date(sale_date),
         sale_terms = str_replace_all(sale_terms, "Not Arms Length", "NOT ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "not arms Length", "NOT ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "valid arms length", "VALID ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "Valid Arms Length", "VALID ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "bank sale used", "BANK SALE USED"),
         sale_terms = str_replace_all(sale_terms, "00-NOT AUDITED", "NOT AUDITED"),
         sale_terms = as_factor(sale_terms))

# Assessments
assessments_clean <- 
  assessments %>% 
  select(-c(propclass )) %>% 
  rename(c(parcel_num = PARCELNO,
           assessed_value = ASSESSEDVALUE,
           taxable_value = TAXABLEVALUE)) %>% 
  mutate(year = as.factor(year))

# Blight

blight_clean <- 
  blight %>% 
  mutate(violation_date = as.Date(violation_date)) %>% 
  rename(parcel_num = parcelno)

# Parcels: Create a parcels tibble that combines historic with all. Can filter down later if needed.

parcels_current_clean <- 
  parcels %>% 
  rename(parcel_num = parcel_number) %>% 
  mutate(zip_code = as.numeric(zip_code),
         property_class = as.factor(property_class))

parcels_historic_clean <- 
  parcels_historic %>% 
  rename(parcel_num = PARCELNO,
         address = PROPADDR,
         zip_code = ZIPCODE,
         taxpayer_1 = TAXPAYER1,
         taxpayer_street = TAXPADDR,
         taxpayer_city = TAXPCITY,
         taxpayer_state = TAXPSTATE,
         taxpayer_zip = TAXPZIP,
         property_class = propclass,
         tax_status = TAXSTATUS,
         total_square_footage = TOTALSQFT,
         total_acreage = TOTALACREAGE,
         frontage = FRONTAGE,
         homestead_pre = PRE,
         sale_price = SALEPRICE,
         sale_date = SALEDATE,
         assessed_value = ASSESSEDVALUE,
         taxable_value = TAXABLEVALUE) %>% 
  mutate(zip_code = as.numeric(zip_code),
         property_class = as.factor(property_class))

parcels_clean <- 
  left_join(parcels_current_clean, parcels_historic_clean)

# Foreclosures (do I need to do some sort of filtering?)

foreclosures_clean <- 
  foreclosures %>% 
  rename(parcel_num = prop_parcelnum)

```


- Visually look at the data, make charts of the distribution of values.
Use the recommendation of the textbook for how to lay this out!

Do I want number of foreclosures by year?


```{r exploratory-analysis}

custom_theme <- theme_bw() +
  theme(plot.title = element_text(size = 9),
        axis.title.x = element_text(size = 9), 
        axis.title.y = element_text(size = 9))

# Get distribution of assessment value by year


assessments_histogram <- 
  assessments_clean %>% 
  ggplot() +
  geom_density(mapping = aes(assessed_value), 
               colour = FALSE, fill = "blue") + 
  ggtitle("Distribution of assessments") + custom_theme

assessments_2011_2016 <- 
  assessments_clean %>% 
  filter(year %in% c(2011, 2012, 2013, 2014, 2015, 2016),
         assessed_value < (sd(assessed_value) * 2)) %>% 
  ggplot() +
  stat_density_ridges(aes(x = assessed_value, y = year),
                      fill = "blue", 
                      colour = "white", 
                      scale = 1, 
                      alpha = 0.9,
                      quantile_lines = TRUE, 
                      quantiles = 2) +
  xlab("Assessment Value") + 
  ylab("Year") + 
  ggtitle("Distribution of Assessements: 2011-2016") +
  custom_theme

assessments_2017_2022 <- 
assessments_clean %>% 
  filter(year %in% c(2017, 2018, 2019, 2020, 2021, 2022),
         assessed_value < (sd(assessed_value) * 2)) %>% 
  ggplot() +
  geom_density_ridges(aes(x = assessed_value, y = year),
                      fill = "blue", 
                      colour = "white", 
                      scale = 1, 
                      alpha = 0.9) +
  xlab("Assessment Value") + 
  ylab("Year") + 
    ggtitle("Distribution of Assessements: 2017-2022") +
  custom_theme

grid.arrange(assessments_2011_2016, assessments_2017_2022, ncol = 2)

# Get distribution of price value by year
# Get 

```

# Section B: Sales Ratio Study

Use cmfproperty to conduct a sales ratio study across the relevant time period. Note that cmfproperty is designed to produce Rmarkdown reports but use the documentation and insert relevant graphs/figures into your report. Look to make this reproducible since you’ll need these methods to analyze your assessment model later on. Detroit has many sales which are not arm’s length (sold at fair market value) so some sales should be excluded, but which ones?
https://erhla.github.io/cmfproperty/articles/cmfproperty.html

Things I want to write:
- What sort of data processing am I doing? What am I removing?
- Lean heavily on the strategy of the CCAO to exclude, then do that. Include
- a link.

Remove data:
- Drop certain sales because of sale_terms; should look at what they mean
- Drop certain sales if they are X (5?) number of standard deviations from the assessment, just like how the CCAO did it. In order to do this, I want to first standardize all of them... There are some goofy different ways of framing this.




```{r cmfproperty-sales-ratio}
#head(cmfproperty::example_data)

# NOTE: Let's 

# formatted_data_ratio <- 
  

# ratios <-
#   cmfproperty::reformat_data(
#     data = sales,
#     sale_col = "SALE_PRICE",
#     assessment_col = "ASSESSED_VALUE",
#     sale_year_col = "SALE_YEAR",
#   )

```


Section C: Explore trends and relationships with property sales using simple regressions
```{r}


```

Section D: Explore trends and relationships with foreclosures using simple regressions

```{r}


```