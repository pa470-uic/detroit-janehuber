---
title: "Part 2"
author: "Jane Huber"
date: "2/20/2022"
output: 
  html_document:
    code_folding: hide
    df_print: paged
    theme: sandstone
    toc: true
editor_options: 
  chunk_output_type: console
---

Jane To-Do:
1. Conclude Part B by making the tables from the textbook, 8.3 and 8.4
Evaluation:
8.3 is false positive/false negative/true positive/true negative.
8.4 gives an analysis of the significance of all of these things.

30 minutes.


2. Part C. Max 2 hours.

3. Grab plots from first part of this assignment, add in limited commentary. Max 1 hour here.





```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE, message = FALSE)
library(tidyverse)
library(lubridate)
library(cmfproperty)
library(purrr)
library(gridExtra)
library(ggplot2)
library(readxl)
library(tidymodels)
library(glmnet)
```

### Part A

```{r download-data, include=FALSE}

con <- DBI::dbConnect(RSQLite::SQLite(), "../database/detroit.sqlite")

# convert to tibble
sales <- dplyr::tbl(con, 'sales') %>% dplyr::collect()
assessments <- dplyr::tbl(con, 'assessments') %>% dplyr::collect()
foreclosures <- dplyr::tbl(con, 'foreclosures') %>% dplyr::collect()
parcels <- dplyr::tbl(con, 'parcels') %>% dplyr::collect()
parcels_historic <- dplyr::tbl(con, 'parcels_historic') %>% dplyr::collect()

# property_classifications <- read_xlsx("files/OFFICE OF THE ASSESSORS_PROPERTY CLASSIFICATIONS -rev.xlsx")
```

```{r data-exploration-cleaning, include = FALSE}
# Sales
# First, we pick only the columns we care about, then standardize the different types of sales terms (in case we want them some day). Finally, we will filter to only include valid arms length sales, following the methodology of the Center of Municipal Finance at the University of Chicago's study "An Evaluation of Residential Property Tax Assessments in the City of Detroit, 2016-2018". Not only does this restrict our data analysis to be more specifically verified, but it will greatly reduce the size of data.

years_for_evaluation <- c('2016', '2017', '2018', '2019')

#remove factor for sale date
sales_clean <- 
  sales %>% 
  select(c(parcel_num, sale_date, sale_price, sale_terms, property_c)) %>% 
  rename(c(prop_class = property_c)) %>% 
  mutate(sale_date = format(as.Date(sale_date), format="%Y"),
         sale_terms = str_replace_all(sale_terms, "Not Arms Length", "NOT ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "not arms length", "NOT ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "valid arms length", "VALID ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "Valid Arms Length", "VALID ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "bank sale used", "BANK SALE USED"),
         sale_terms = str_replace_all(sale_terms, "00-NOT AUDITED", "NOT AUDITED"),
         prop_class = as_factor(prop_class), 
         sale_terms = as_factor(sale_terms)) %>% 
  filter(sale_terms == "VALID ARMS LENGTH",
         sale_date %in% years_for_evaluation,
         prop_class == '401')

# Assessments
assessments_clean <-
  assessments %>%
  rename(c(parcel_num = PARCELNO,
           assessed_value = ASSESSEDVALUE,
           taxable_value = TAXABLEVALUE,
           assessment_year = year,
           prop_class = propclass)) %>% 
  mutate(prop_class = as_factor(prop_class)) %>% 
  filter(assessed_value > 2000)

# Parcels: Create a parcels tibble that combines historic with all. Can filter down later if needed.
parcels_current_clean <-
  parcels %>%
  rename(parcel_num = parcel_number) %>%
  mutate(zip_code = as.numeric(zip_code),
         property_class = as.factor(property_class))

parcels_historic_clean <-
  parcels_historic %>%
  rename(parcel_num = PARCELNO,
         address = PROPADDR,
         zip_code = ZIPCODE,
         taxpayer_1 = TAXPAYER1,
         taxpayer_street = TAXPADDR,
         taxpayer_city = TAXPCITY,
         taxpayer_state = TAXPSTATE,
         taxpayer_zip = TAXPZIP,
         property_class = propclass,
         tax_status = TAXSTATUS,
         total_square_footage = TOTALSQFT,
         total_acreage = TOTALACREAGE,
         frontage = FRONTAGE,
         homestead_pre = PRE,
         sale_price = SALEPRICE,
         sale_date = SALEDATE,
         assessed_value = ASSESSEDVALUE,
         taxable_value = TAXABLEVALUE) %>%
  mutate(zip_code = as.numeric(zip_code),
         property_class = as.factor(property_class))

parcels_clean <-
  left_join(parcels_current_clean, parcels_historic_clean) %>% 
  select(c(ward, parcel_num, council_district, zip_code))


sales_and_assessments <- 
  left_join(sales_clean, assessments_clean) %>% 
  filter(!is.na(sale_date)) %>% 
  mutate(sale_date = as.numeric(sale_date))

sales_assessments_parcels <- 
  left_join(sales_and_assessments, parcels_clean) 
```

### Part B

```{r classify-home-as-overassessed}

# Get data filtered
overassessed <- 
sales_assessments_parcels %>% 
  filter(sale_date == 2016,
         assessment_year == 2016) %>% 
  mutate(overassessed = as_factor(if_else(sale_price < (assessed_value * 2),
                                "YES",
                                "NO")))

split <- rsample::initial_split(overassessed)

train <- training(split)
test <- testing(split)


# Wanted to use a random forest here, but couldn't figure out the best way to visualize
# Would love to discuss in class further.

# rand_forest_model <- 
# rand_forest(trees = 1000, min_n = 5) %>% 
#   set_engine("ranger", verbose = TRUE) %>% 
#   set_mode("classification") %>%
#   translate()

log_model <- 
  logistic_reg() %>%
  set_engine('glm') %>%
  set_mode('classification')

overassessed_recipe <- 
  recipe(overassessed ~ sale_price + ward + zip_code,
      data = train) %>%
  step_other(ward, threshold = 0.01) %>% 
  step_other(zip_code, threshold = 0.01) %>% 
  step_unknown(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors())
  
wflow <- 
  workflow() %>%
  add_model(log_model) %>% 
  add_recipe(overassessed_recipe)


#Evaluate model
rf_fit <- fit(wflow, overassessed)

# rf_fit %>% tidy() %>% view()

homes_2016 <- 
  train %>% 
  filter(sale_date == 2016)

overassessment_predictions <- 
  augment(rf_fit, homes_2016)

```

Our model, it turns out, is relatively effective at determining whether or not a property will be overassesed.

```{r evaluate-overassessments}

overassment_evaluation <- 
  left_join(overassessment_predictions, overassessed) %>% 
  group_by(overassessed) %>% 
  summarize(predicted_not_overassessed = sum(.pred_class == "NO"),
            predicted_overassessed = sum(.pred_class == "YES"))

overassment_evaluation


# Create a classifier metrics table to help us further evaluate our model.

true_negative <- overassment_evaluation$predicted_not_overassessed[1]
false_negative <- overassment_evaluation$predicted_not_overassessed[2]
false_positive <- overassment_evaluation$predicted_overassessed[1]
true_positive <- overassment_evaluation$predicted_overassessed[2]

true_positive_rate <- true_positive / (true_positive + false_negative)
true_negative_rate <- true_negative / (true_negative + false_positive)
false_positive_rate <- false_positive /(false_positive + true_negative)
false_negative_rate <- false_negative / (false_negative + true_positive)
positive_predictive_value <- true_positive / (true_positive + false_positive)

classifier_metrics_table <- tibble(measurement = c("true positive rate", 
                                                   "true negative rate",
                                                   "false positive rate",
                                                   "false positive rate",
                                                   "positive predictive value"), 
                                   `value` = c(true_positive_rate, 
                                               true_negative_rate,
                                               false_positive_rate,
                                               false_negative_rate,
                                               positive_predictive_value))

classifier_metrics_table

```

Furthermore, an ROC curve further demonstrates the effectiveness of our model is at determining whether a property is likely to be overassessed.

```{r roc-curve-overassessments}

roc_curve <- yardstick::roc_curve(data = overassessment_predictions, truth = overassessed, .pred_NO)

autoplot(roc_curve)
```

### Part C

```{r sale-predictions-2019}

split_sales <- rsample::initial_split(sales_assessments_parcels)

train_sales <- training(split_sales)
test_sales <- testing(split_sales)

linear_model_sales <- 
  linear_reg() %>% 
  set_engine("lm") 

sale_price_recipe <- 
  recipe(sale_price ~ ward + zip_code + assessed_value,
      data = train_sales) %>%
  step_other(ward, threshold = 0.01) %>% 
  step_other(zip_code, threshold = 0.01) %>% 
  step_unknown(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors())
  
sale_wflow <- 
  workflow() %>%
  add_model(linear_model_sales) %>% 
  add_recipe(sale_price_recipe)

# Fit the model
rf_fit_sales <- fit(sale_wflow, train_sales)

rf_fit_sales %>% tidy() %>% view()

sales_2019 <- 
  test_sales %>% 
  filter(sale_date == 2019)

sale_price_predictions <- 
  augment(rf_fit_sales, sales_2019)

sale_price_predictions

```


```{r mape-mpse-analysis}

yardstick::mape(sale_price_predictions,
     truth = sale_price,
     estimate = .pred)


yardstick::rmse(sale_price_predictions,
     truth = sale_price,
     estimate = .pred)

```
