---
title: "Part 2"
author: "Jane Huber"
date: "2/20/2022"
output: 
  html_document:
    code_folding: hide
    df_print: paged
    theme: sandstone
    toc: true
editor_options: 
  chunk_output_type: console
---

Jane To-Do:
1. Conclude Part B by making the tables from the textbook, 8.3 and 8.4
Evaluation:
8.3 is false positive/false negative/true positive/true negative.
8.4 gives an analysis of the significance of all of these things.

30 minutes.


2. Part C. Max 2 hours.

3. Grab plots from first part of this assignment, add in limited commentary. Max 1 hour here.





```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE, message = FALSE)
library(tidyverse)
library(lubridate)
library(cmfproperty)
library(purrr)
library(gridExtra)
library(ggplot2)
library(readxl)
library(tidymodels)
```

```{r download-data, include=FALSE}

con <- DBI::dbConnect(RSQLite::SQLite(), "database/detroit.sqlite")

# convert to tibble
sales <- dplyr::tbl(con, 'sales') %>% dplyr::collect()
assessments <- dplyr::tbl(con, 'assessments') %>% dplyr::collect()
foreclosures <- dplyr::tbl(con, 'foreclosures') %>% dplyr::collect()
parcels <- dplyr::tbl(con, 'parcels') %>% dplyr::collect()
parcels_historic <- dplyr::tbl(con, 'parcels_historic') %>% dplyr::collect()

# property_classifications <- read_xlsx("files/OFFICE OF THE ASSESSORS_PROPERTY CLASSIFICATIONS -rev.xlsx")
```

```{r data-exploration-cleaning, include = FALSE}
# Sales
# First, we pick only the columns we care about, then standardize the different types of sales terms (in case we want them some day). Finally, we will filter to only include valid arms length sales, following the methodology of the Center of Municipal Finance at the University of Chicago's study "An Evaluation of Residential Property Tax Assessments in the City of Detroit, 2016-2018". Not only does this restrict our data analysis to be more specifically verified, but it will greatly reduce the size of data.

years_for_evaluation <- c('2016', '2017', '2018', '2019')

#remove factor for sale date
sales_clean <- 
  sales %>% 
  select(c(parcel_num, sale_date, sale_price, sale_terms, property_c)) %>% 
  rename(c(prop_class = property_c)) %>% 
  mutate(sale_date = format(as.Date(sale_date), format="%Y"),
         sale_terms = str_replace_all(sale_terms, "Not Arms Length", "NOT ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "not arms length", "NOT ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "valid arms length", "VALID ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "Valid Arms Length", "VALID ARMS LENGTH"),
         sale_terms = str_replace_all(sale_terms, "bank sale used", "BANK SALE USED"),
         sale_terms = str_replace_all(sale_terms, "00-NOT AUDITED", "NOT AUDITED"),
         prop_class = as_factor(prop_class), 
         sale_terms = as_factor(sale_terms)) %>% 
  filter(sale_terms == "VALID ARMS LENGTH",
         sale_date %in% years_for_evaluation,
         prop_class == '401')

# Assessments
assessments_clean <-
  assessments %>%
  rename(c(parcel_num = PARCELNO,
           assessed_value = ASSESSEDVALUE,
           taxable_value = TAXABLEVALUE,
           assessment_year = year,
           prop_class = propclass)) %>% 
  mutate(prop_class = as_factor(prop_class)) %>% 
  filter(assessed_value > 2000)

# Parcels: Create a parcels tibble that combines historic with all. Can filter down later if needed.
parcels_current_clean <-
  parcels %>%
  rename(parcel_num = parcel_number) %>%
  mutate(zip_code = as.numeric(zip_code),
         property_class = as.factor(property_class))

parcels_historic_clean <-
  parcels_historic %>%
  rename(parcel_num = PARCELNO,
         address = PROPADDR,
         zip_code = ZIPCODE,
         taxpayer_1 = TAXPAYER1,
         taxpayer_street = TAXPADDR,
         taxpayer_city = TAXPCITY,
         taxpayer_state = TAXPSTATE,
         taxpayer_zip = TAXPZIP,
         property_class = propclass,
         tax_status = TAXSTATUS,
         total_square_footage = TOTALSQFT,
         total_acreage = TOTALACREAGE,
         frontage = FRONTAGE,
         homestead_pre = PRE,
         sale_price = SALEPRICE,
         sale_date = SALEDATE,
         assessed_value = ASSESSEDVALUE,
         taxable_value = TAXABLEVALUE) %>%
  mutate(zip_code = as.numeric(zip_code),
         property_class = as.factor(property_class))

parcels_clean <-
  left_join(parcels_current_clean, parcels_historic_clean) %>% 
  select(c(ward, parcel_num, council_district, zip_code))


sales_and_assessments <- 
  left_join(sales_clean, assessments_clean) %>% 
  filter(!is.na(sale_date)) %>% 
  mutate(sale_date = as.numeric(sale_date))

sales_assessments_parcels <- 
  left_join(sales_and_assessments, parcels_clean) 
```
Decision here: do I want to use logistic regression or random forest to attempt to classify predictions?

Remember: use data from 2016.

Evaluate using: classification metrics from tables 8.3 and 8.4 from the textbook and the classification probability metric ROC curves.

```{r classify-home-as-overassessed}

# Get data filtered
overassessed <- 
sales_assessments_parcels %>% 
  filter(sale_date == 2016,
         assessment_year == 2016) %>% 
  mutate(overassessed = as_factor(if_else(sale_price < (assessed_value * 2),
                                "YES",
                                "NO")))

split <- rsample::initial_split(overassessed)

train <- training(split)
test <- testing(split)


# Wanted to use a random forest here, but couldn't figure out the best way to visualize
# Would love to discuss in class further.

# rand_forest_model <- 
# rand_forest(trees = 1000, min_n = 5) %>% 
#   set_engine("ranger", verbose = TRUE) %>% 
#   set_mode("classification") %>%
#   translate()

log_model <- 
  logistic_reg() %>%
  set_engine('glm') %>%
  set_mode('classification')

overassessed_recipe <- 
  recipe(overassessed ~ sale_price + ward + zip_code,
      data = train) %>%
  step_other(ward, threshold = 0.01) %>% 
  step_other(zip_code, threshold = 0.01) %>% 
  step_unknown(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors())
  
wflow <- 
  workflow() %>%
  add_model(log_model) %>% 
  add_recipe(overassessed_recipe)


#Evaluate model
rf_fit <- fit(wflow, overassessed)

# rf_fit %>% tidy() %>% view()

homes_2016 <- 
  train %>% 
  filter(sale_date == 2016)

overassessment_predictions <- 
  augment(rf_fit, homes_2016)


```

Our model, it turns out, is relatively effective at determining whether or not a property will be overassesed. You can see that the Positive Predictive Value (PPV) is 83%.


```{r evaluate-overassessments}

overassment_evaluation <- 
  left_join(overassessment_predictions, overassessed) %>% 
  group_by(overassessed) %>% 
  summarize(predicted_not_overassessed = sum(.pred_class == "NO"),
            predicted_overassessed = sum(.pred_class == "YES"))

overassment_evaluation




```

Furthermore, an ROC curve further demonstrates how effective our model is at determining whether a property is likely to be overassessed.

```{r roc-curve}

roc_curve <- yardstick::roc_curve(data = overassessment_predictions, truth = overassessed, .pred_NO)


# roc_curve
autoplot(roc_curve)
```

Need to do a yardstick evaluation at the bottom of this work:
```{r}

# yardstick::mape(divvy_preds, 
#      truth = rides,
#      estimate = .pred)
# yardstick::rmse(divvy_preds, 
#      truth = rides,
#      estimate = .pred)
```
